{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from championWrapper import ChampionWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = pd.read_csv('pb_table.csv', index_col=False)\n",
    "champs = ChampionWrapper()\n",
    "\n",
    "num_champs = len(champs.champToID)\n",
    "num_champs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the input frames of hero choices by name\n",
    "isolated_input = in_data[['BB1', 'RB1', 'BB2', 'RB2', 'BB3', 'RB3', 'BP1', 'RP1','RP2','BP2','BP3', 'RP3', 'RB4','BB4', 'RB5', 'BB5', 'RP4', 'BP4','BP5', 'RP5']]\n",
    "isolated_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe to Numpy\n",
    "inputnpArray = isolated_input.to_numpy()\n",
    "inputnpArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy convert Names to Ids\n",
    "for match in range(len(inputnpArray)):\n",
    "    for column in range(len(inputnpArray[match])):\n",
    "        inputnpArray[match][column] = champs.cNameToId(inputnpArray[match][column])\n",
    "\n",
    "inputnpArray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the data   \n",
    "In Raw form we want to make it into [In][Label] sets to    \n",
    "use in our Sequence to Sequence model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have the data\n",
    "# In Raw form we want to make it into [In][Label] sets to \n",
    "# use in our Sequence to Sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberpd = pd.DataFrame(inputnpArray, columns=['BB1', 'RB1', 'BB2', 'RB2', 'BB3', 'RB3', 'BP1', 'RP1','RP2','BP2','BP3', 'RP3', 'RB4','BB4', 'RB5', 'BB5', 'RP4', 'BP4','BP5', 'RP5'])\n",
    "print(numberpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf, testdf = train_test_split(numberpd, test_size=0.2)\n",
    "testdf, valdf = train_test_split(testdf, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfl = tf.keras.layers\n",
    "n_features=num_champs\n",
    "results = {}\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "the_loss = 'categorical_crossentropy'\n",
    "num_epochs=500\n",
    "r_state = 20\n",
    "tf.random.set_seed=r_state\n",
    "from WindowGenerator import SplitGen\n",
    "\n",
    "splitter = SplitGen()\n",
    "train, test = train_test_split(inputnpArray, test_size=0.2, random_state=r_state)\n",
    "test, val = train_test_split(test, test_size=0.5, random_state=r_state)\n",
    "\n",
    "i=18\n",
    "o=2\n",
    "f=num_champs\n",
    "\n",
    "X_train, y_train = splitter.split_sequences(train, i, o, f)\n",
    "X_test, y_test = splitter.split_sequences(test, i, o, f)\n",
    "X_val, y_val = splitter.split_sequences(val, i, o, f)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lSTM_model = tf.keras.Sequential([\n",
    "    tfl.LSTM(512, activation='relu', input_shape=(i, f)),\n",
    "    tfl.RepeatVector(o),\n",
    "    tfl.Dense(64),\n",
    "    tfl.Dense(f, activation='softmax')\n",
    "])\n",
    "lSTM_model.compile(optimizer='adam', loss=the_loss, metrics=['accuracy'])\n",
    "\n",
    "lSTM_model.fit(X_train,y_train, validation_data=(X_val, y_val), callbacks=[es], epochs=num_epochs)\n",
    "print(\"\\n\\neval-----\")\n",
    "results['lstm']=lSTM_model.evaluate(X_test, y_test)\n",
    "print(results['lstm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=lSTM_model\n",
    "print(model.evaluate(X_train, y_train))\n",
    "print(model.evaluate(X_val, y_val))\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = tf.keras.Sequential([\n",
    "    tfl.SimpleRNN(512, input_shape=(i, f)),\n",
    "    tfl.Dense(128),\n",
    "    tfl.Dense(f, activation='softmax'),\n",
    "    tfl.RepeatVector(o)\n",
    "\n",
    "    \n",
    "])\n",
    "rnn_model.compile(optimizer='adam', loss=the_loss, metrics=['accuracy'])\n",
    "\n",
    "rnn_model.fit(X_train,y_train, validation_data=(X_val, y_val), callbacks=[es], epochs=num_epochs)\n",
    "print(\"\\n\\neval-----\")\n",
    "results['rnn']=rnn_model.evaluate(X_test, y_test)\n",
    "print(results['rnn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=rnn_model\n",
    "print(model.evaluate(X_train, y_train))\n",
    "print(model.evaluate(X_val, y_val))\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_LSTM_model = tf.keras.Sequential([\n",
    "    tfl.Bidirectional(tfl.LSTM(512, activation='relu', input_shape=(i, f))),\n",
    "    tfl.RepeatVector(o),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(256, activation='relu'),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.TimeDistributed(tfl.Dense(256)),\n",
    "    tfl.Dropout(0.4),\n",
    "    tfl.TimeDistributed(tfl.Dense(f, activation='softmax'))\n",
    "\n",
    "\n",
    "])\n",
    "bi_LSTM_model.compile(optimizer='adam', loss=the_loss, metrics=['accuracy'])\n",
    "\n",
    "bi_LSTM_model.fit(X_train,y_train, validation_data=(X_val, y_val), callbacks=[es],verbose=1, epochs=num_epochs)\n",
    "print(\"\\n\\neval-----\")\n",
    "results['bilstm']=bi_LSTM_model.evaluate(X_test, y_test)\n",
    "print(results['bilstm'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=bi_LSTM_model\n",
    "print(model.evaluate(X_train, y_train))\n",
    "print(model.evaluate(X_val, y_val))\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['bilstm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 3\n",
    "conv_model = tf.keras.Sequential([\n",
    "\n",
    " tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(32, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tfl.Dense(128),\n",
    "    tf.keras.layers.Dense(o*f,\n",
    "                          kernel_initializer=tf.initializers.zeros(), activation='softmax'),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([o, f])\n",
    "\n",
    "])\n",
    "conv_model.compile(optimizer='adam', loss=the_loss, metrics=['accuracy'])\n",
    "\n",
    "conv_model.fit(X_train,y_train, validation_data=(X_val, y_val), callbacks=[es], epochs=num_epochs)\n",
    "print(\"\\n\\neval-----\\n\")\n",
    "results['conv']=conv_model.evaluate(X_test, y_test)\n",
    "print(results['conv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=conv_model\n",
    "print(model.evaluate(X_train, y_train))\n",
    "print(model.evaluate(X_val, y_val))\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(32, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    tfl.MaxPooling1D(pool_size=2),\n",
    "    tfl.Flatten(),\n",
    "    tfl.RepeatVector(o),\n",
    "    tfl.LSTM(512, activation='relu', return_sequences=True), \n",
    "    tfl.TimeDistributed(tfl.Dense(256,activation='relu')),\n",
    "    tfl.TimeDistributed(tfl.Dense(f))\n",
    "])\n",
    "\n",
    "clstm_model.compile(optimizer='adam', loss=the_loss, metrics=['accuracy'])\n",
    "\n",
    "clstm_model.fit(X_train,y_train, validation_data=(X_val, y_val), callbacks=[es], epochs=num_epochs)\n",
    "print(\"\\neval-----\\n\")\n",
    "results['clstm']=clstm_model.evaluate(X_test, y_test)\n",
    "print(results['clstm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "win = max(results, key=lambda x: results[x][1])\n",
    "print(f'max on test: {win}: {results[win]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [clstm_model, bi_LSTM_model, lSTM_model,hydoubleLSTM_model,doubleLSTM_model,bidoubleLSTM_model,rnn_model,singrnn_model,conv_model]\n",
    "losses = ['mse', 'categorical_crossentropy', 'binary_crossentropy']\n",
    "names = ['clstm', 'bilstm', 'lstm', 'hylstm', 'doubllstm', 'bidoublels', 'rnn', 'singrnn', 'conv']\n",
    "results = {}\n",
    "for loss in losses:\n",
    "    the_loss = loss\n",
    "    print(loss)\n",
    "    for model, name in tqdm(zip(models, names)):\n",
    "        print(name)\n",
    "        model.compile(optimizer='adam', loss=the_loss, metrics=['accuracy'])\n",
    "        model.fit(X_train,y_train, validation_data=(X_val, y_val), callbacks=[es], epochs=num_epochs, verbose=0)\n",
    "        results[f'{loss}_{name}']= model.evaluate(X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "win = max(results, key=lambda x: results[x][1])\n",
    "print(f'max on test: {win}: {results[win]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [clstm_model, bi_LSTM_model, lSTM_model,hydoubleLSTM_model,doubleLSTM_model,bidoubleLSTM_model,rnn_model,singrnn_model,conv_model]\n",
    "losses = ['mse', 'categorical_crossentropy', 'binary_crossentropy']\n",
    "names = ['clstm', 'bilstm', 'lstm', 'hylstm', 'doubllstm', 'bidoublels', 'rnn', 'singrnn', 'conv']\n",
    "for loss in losses:\n",
    "    the_loss = loss\n",
    "    print(loss)\n",
    "    for model, name in tqdm(zip(models, names)):\n",
    "        print(name)\n",
    "        model.compile(optimizer='adam', loss=the_loss, metrics=['accuracy'])\n",
    "        model.fit(X_train,y_train, validation_data=(X_val, y_val), epochs=num_epochs, verbose=0)\n",
    "        results[f'long_{loss}_{name}']= model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "win = max(results, key=lambda x: results[x][1])\n",
    "print(f'max on test: {win}: {results[win]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
